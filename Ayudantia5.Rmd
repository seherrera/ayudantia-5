---
title: "Ayudantia 5 Clusters"
output: github_document
---

# Actividad Ayudantia 5

Realizar análisis de clustering (K-means, incluye preprocesamiento de la data) e índices de evaluación para el archivo "sandwiches.csv" tomando las columnas de nota y precio. Hacer análisis para diferentes K y/o medidas de distancia para que vean cómo se comporta el clustering.

# Algoritmo de clustering base:

## K-Medias

Para el análisis de clusters vamos a analizar la data de  “sanguchez.csv” que contiene la información de sandwiches
```{r load data}
library(tidyverse)

data <- read.csv(file.choose(), sep = ";", header= TRUE )

head(data)

summary(data)

```

Para clusterizar vamos a seleccionar las variables de nota,precio. Para analizar el comportamiento vamos a excluir url,direccion, texto, ingredientes y local. 

## funcion que pasa las notas a valor numerico
```{r}
data$Precio <- as.numeric(gsub('[$.aprox]', '', data$Precio))
data$nota <- as.numeric(gsub('[$.aprox]', '', data$nota))
```

```{r preproc data}
#Se borran los datos nulos
data <- data[,!(colnames(data) %in% c("url", "Direccion", "texto", "Ingredientes", "Local"))] 
data <- data[!is.na(data$Precio),]
data <- data[!is.na(data$nota),]

escala_data = scale(data) %>% as_tibble()

escala_data %>% summary()
escala_data$Precio %>% as.numeric()
escala_data$nota %>% as.integer()


```

Ya tenemos escalada la data, vamos a aplicar el algoritmo de kmedias, que viene implementado en R base. 
Para probar, vamos a aplicar kmedias con k = 10

## Analisis Cluster K = 10
```{r clus k10}
modelo_kmeans <- kmeans(escala_data, centers = 10)
modelo_kmeans2 <- kmeans(data, centers = 10)

# creo la variable cluster en la tabla escala_data
escala_data$clus <- modelo_kmeans$cluster %>% as.factor()
data$clus <- modelo_kmeans2$cluster %>% as.factor()

ggplot(escala_data, aes(nota, Precio, color=clus)) +
  geom_point(alpha=0.5, show.legend = T) +
  theme_bw()

ggplot(data, aes(nota ,Precio, color=clus)) +
  geom_point(alpha=0.5, show.legend = T) +
  theme_bw()

info_clus <- modelo_kmeans$centers
info_clus2 <- modelo_kmeans2$centers

info_clus
info_clus2
```

## Evolución suma de cuadrados intra-cluster en la medida que aumentamos el numero de k
```{r evolucion sse}
SSinterior <- numeric(30)

for(k in 1:30){
  modelo <- kmeans(escala_data, centers = k)
  SSinterior[k] <- modelo$tot.withinss
}

plot(SSinterior)
```

## Metodo del Codo 2

```{r metodo codo2}
#Calculando K para Data normalizada
k.max <- 30
wss1 <- sapply(1:k.max, 
               function(k){kmeans(escala_data, k, nstart=50,iter.max = 8)$tot.withinss})
wss2 <- sapply(1:k.max, 
               function(k){kmeans(data, k, nstart=50,iter.max = 8)$tot.withinss})

#wss1
plot(1:k.max, wss1,
     type="b", pch = 19, frame = FALSE, 
     xlab="Numeros de clusters K",
     ylab="Total within-clusters sum of squares")

plot(1:k.max, wss2,
     type="b", pch = 19, frame = FALSE, 
     xlab="Numeros de clusters K",
     ylab="Total within-clusters sum of squares")
```

# Evaluacion

Existen diversos metodos de evaluacion de calidad de los clusters resultantes. 

## Inspeccion visual
```{r insp visual}

escala_data$clus <- as.numeric(escala_data$clus)
data$clus <- as.numeric(data$clus)

# uso distancia euclidiana
tempDist <- dist(escala_data) %>% as.matrix()

#reordeno filas y columnas en base al cluster obtenido
index <- sort(modelo_kmeans$cluster, index.return=TRUE)
tempDist <- tempDist[index$ix,index$ix]
rownames(tempDist) <- c(1:nrow(escala_data))
colnames(tempDist) <- c(1:nrow(escala_data))

image(tempDist)
```

## Estadistico de Hopkins. 
```{r estad hopkins}
library(factoextra)

#Calcula el hopkins statistic 
res <- get_clust_tendency(escala_data, n = 30, graph = FALSE)
res2 <- get_clust_tendency(data, n = 30, graph = FALSE)

print(res)
print(res2)
```

## Indice de correlación
```{r coef correlacion}
#Correlation
#construyo matriz de correlacion ideal (cada entidad correlaciona 1 con su cluster)
tempMatrix <- matrix(0, nrow = nrow(data), ncol = nrow(data))
tempMatrix[which(index$x==1), which(index$x==1)]  <- 1
tempMatrix[which(index$x==2), which(index$x==2)]  <- 1
tempMatrix[which(index$x==3), which(index$x==3)]  <- 1
tempMatrix[which(index$x==4), which(index$x==4)]  <- 1
tempMatrix[which(index$x==5), which(index$x==5)]  <- 1
tempMatrix[which(index$x==6), which(index$x==6)]  <- 1
tempMatrix[which(index$x==7), which(index$x==7)]  <- 1
tempMatrix[which(index$x==8), which(index$x==8)]  <- 1
tempMatrix[which(index$x==9), which(index$x==9)]  <- 1
tempMatrix[which(index$x==10), which(index$x==10)] <- 1

#construyo matriz de disimilitud
tempDist2 <- 1/(1+tempDist)

#Calcula correlacion 
cor <- cor(tempMatrix[upper.tri(tempMatrix)],tempDist2[upper.tri(tempDist2)])

print(cor)
```

## Indice de cohesión y el de separación.
```{r coef cohesion y separacion}
library(flexclust) # usaremos la distancia implementada en flexclus (dist2) que maneja mejor objetos de diferente tamaño
#escala_data <- apply(escala_data,2,as.numeric)

#Cohesion
withinCluster <- numeric(10)
for (i in 1:10){
  tempdata <- escala_data[which(modelo_kmeans$cluster == i),]
  withinCluster[i] <- sum(dist2(tempdata,colMeans(tempdata))^2)
}
cohesion = sum(withinCluster)
#es equivalente a model$tot.withinss en k-means
print(c(cohesion, modelo_kmeans$tot.withinss))

#Separation
meandata <- colMeans(escala_data)
SSB <- numeric(10)
for (i in 1:10){
  tempdata <- escala_data[which(modelo_kmeans$cluster==i),]
  SSB[i] <- nrow(tempdata)*sum((meandata-colMeans(tempdata))^2)
}
separation = sum(SSB)

print(separation)
```

## Coeficiente de silueta
```{r coef silueta}
library(cluster)

coefSil <- silhouette(modelo_kmeans$cluster,dist(escala_data))
summary(coefSil)

#visualizamos el codigo de silueta de cada cluster
fviz_silhouette(coefSil) + coord_flip()
```

## Utilizamos el coeficiente de silueta para encontrar el mejor valor de K
```{r valor k silueta}

coefSil=numeric(30)
for (k in 2:30){
  modelo <- kmeans(escala_data, centers = k)
  temp <- silhouette(modelo$cluster,dist(escala_data))
  coefSil[k] <- mean(temp[,3])
}
tempDF=data.frame(CS=coefSil,K=c(1:30))

ggplot(tempDF, aes(x=K, y=CS)) + 
  geom_line() +
  scale_x_continuous(breaks=c(1:30))
```